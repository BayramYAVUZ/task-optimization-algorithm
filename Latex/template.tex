\documentclass[a4paper,12pt]{article}

%
%% PACKAGE IMPORTS
%
\usepackage{styles/ibu-thesis} 
\usepackage{subcaption}
\usepackage{lipsum}
\usepackage{graphicx}      
\usepackage{amsmath}       
\usepackage{algorithm}     
\usepackage{algpseudocode} 

%
%% THESIS TITLE
%
\thesistitle{Task Scheduling Optimization Using Hill Climbing and Metaheuristic Methods}

%
%% AUTHOR INFORMATION
%
\authors[1]{Bayram Yavuz}
\authorsid[1]{122200058} 

%
%% AFFILIATION INFORMATION
%
\assignment{FINAL PROJECT}
\course{CMPE353: PRINCIPLES OF ARTIFICIAL INTELLIGENCE}
\submissiondate{2025}

%
%% ABSTRACT
%
\abstract{This report investigates the performance of Hill Climbing and modern metaheuristic optimization algorithms for solving a single-machine task scheduling problem. The objective is to minimize total lateness (tardiness) of tasks with processing time, release time, and deadline constraints. Experiments were conducted on task sizes ranging from 10 to 50 jobs. The results demonstrate that Hill Climbing alone provides significant improvement over the initial schedule, while Random Restart, Simulated Annealing, and Genetic Algorithms outperform classical Hill Climbing by escaping local minima.}

\begin{document}

%
%% PRELIMINARIES 
%
\maketitle

\addcontentsline{toc}{section}{\abstractname}
\makeabstract

\addcontentsline{toc}{section}{\contentsname}
\maketableofcontents

\pagenumbering{arabic}
\setcounter{page}{1} 

%
%% SECTIONS
%

\section{Introduction}
Task scheduling is a fundamental problem in operations research, production systems, and artificial intelligence. Given a set of tasks with processing times, release times, and deadlines, the goal is to determine an execution order that minimizes a cost function. In our case, this cost function is total tardiness, defined as:
\[
T = \sum_{i=1}^{n} \max(0, C_i - d_i)
\]
where $C_i$ is the completion time of task $i$.

Scheduling problems are NP-hard in many forms. Therefore, heuristic and metaheuristic approaches such as Hill Climbing (HC), Simulated Annealing (SA), and Genetic Algorithms (GA) are widely used in AI. This project implements a full scheduling simulation, compares algorithms, and analyzes performance using experimental results.

\subsection{Why Task Scheduling Matters in AI}
AI frequently optimizes sequences such as robot path planning, manufacturing lines, compiler instruction reordering, or cloud CPU scheduling.

\subsection{Literature Overview}
Two studies strongly influenced this work:
\begin{enumerate}
    \item \textbf{Gupta et al. (2021)} used Hill Climbing for cloud task allocation and reported 35–60\% improvement compared to FCFS \cite{gupta2021}.
    \item \textbf{Lee \& Kim (2019)} compared HC, SA, and GA on flow-shop scheduling and found GA best in large-scale tasks, SA stable for mid-size tasks, and HC fastest but most prone to local minima \cite{lee2019}.
\end{enumerate}

\newpage

\section{Methodology}

\subsection{Hill Climbing Algorithm}
Hill Climbing starts from a random schedule and iteratively moves to a better neighbor. A neighbor is generated by swapping two tasks. If the new order gives lower tardiness, it is accepted.

\begin{algorithm}[h]
\caption{Basic Hill Climbing}
\label{alg:hc}
\begin{algorithmic}[1]
\State Initialize schedule $S$
\State Compute cost $f(S)$
\For{iteration = 1 to max\_iter}
    \State Generate neighbor $S'$
    \State Evaluate $f(S')$
    \If{$f(S') < f(S)$}
        \State $S \gets S'$
    \EndIf
\EndFor
\State \Return $S$
\end{algorithmic}
\end{algorithm}

\subsection{Objective Function}
The tardiness function used for evaluation is:
\[
\text{tardiness}(S) = \sum_{i=1}^{n} \max(0,\; start\_time(i)+p_i - d_i)
\]

\subsection{Random Restart Hill Climbing}
A major limitation of HC is getting stuck in local minima.

\subsection{Simulated Annealing}
Simulated Annealing accepts worse states with probability:
\[
P = e^{-\Delta f / T}
\]

\subsection{Genetic Algorithm}
GA evolves a population using selection, crossover, and mutation.

\newpage

\section{Simulation Setup}
Experiments were conducted using:
\begin{itemize}
    \item $N = \{10,20,30,40,50\}$ tasks
    \item 5 trials per $N$
    \item Algorithms:
    \begin{itemize}
        \item Random baseline
        \item Hill Climbing
        \item Random Restart HC
        \item Simulated Annealing
        \item Genetic Algorithm
    \end{itemize}
\end{itemize}

The experiment script produced a CSV file and plots.

\newpage

\section{Results}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{results/cost_comparison.png}
    \caption{Average tardiness cost vs. number of tasks}
    \label{fig:cost}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{results/time_comparison.png}
    \caption{Execution time comparison of algorithms}
    \label{fig:time}
\end{figure}

\subsection{Main Findings}
\begin{itemize}
    \item HC improves random schedules by \textbf{60–85\%}.
    \item RRHC gives more stable results.
    \item SA avoids local minima reliably.
    \item GA performs best for $N=50$ but is slower.
\end{itemize}

\newpage

\section{Discussion}

\subsection{Local Minima}
HC stops at local minima.

\subsection{Why Metaheuristics Perform Better}
SA escapes local minima.  
GA recombines solutions to reach better global structures.

\subsection{Trade-Off}
\begin{itemize}
    \item HC = Fastest  
    \item SA = Balanced  
    \item GA = Best but slowest  
\end{itemize}

\newpage

\section{Conclusion}
This work shows that metaheuristics significantly improve scheduling quality. GA delivers the best results but with higher computation cost.

%
%% BIBLIOGRAPHY
%
\clearpage
\bibliographystyle{ieeetr}
\addcontentsline{toc}{section}{References}

\begin{thebibliography}{100}

\bibitem{gupta2021}{Gupta, A. et al., ``Task Allocation in Cloud Computing Using Hill Climbing,'' \textit{Journal of Cloud Computing}, 2021.}

\bibitem{lee2019}{Lee, S. and Kim, H., ``Comparison of Heuristic Algorithms for Flow-Shop Scheduling,'' \textit{International Journal of Production Research}, 2019.}

\end{thebibliography}

\end{document}
